import streamlit as st
import nltk
import io
from PyPDF2 import PdfReader
from docx import Document
from transformers import GPT2Tokenizer, GPT2LMHeadModel
import torch
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from nltk.util import ngrams
from nltk.lm.preprocessing import pad_sequence, padded_everygram_pipeline
from nltk.lm import MLE, Vocabulary
from nltk.corpus import stopwords
import string
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer

nltk.download('punkt')
nltk.download('brown')
nltk.download('stopwords')

# Load GPT-2 tokenizer and model
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')
gpt2_model = GPT2LMHeadModel.from_pretrained('gpt2')

# Load the plagiarism detection model and vectorizer
plagiarism_model = pickle.load(open('C:/Users/ASUS/Desktop/PLAGY/with_llm.py/model.pkl', 'rb'))
tfidf_vectorizer = pickle.load(open('C:/Users/ASUS/Desktop/PLAGY/with_llm.py/tfidf_vectorizer.pkl', 'rb'))

def preprocess_text(text):
    tokens = nltk.word_tokenize(text.lower())
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]
    return tokens

def plot_most_common_words(text):
    tokens = preprocess_text(text)
    word_freq = nltk.FreqDist(tokens)
    most_common_words = word_freq.most_common(10)

    words, counts = zip(*most_common_words)

    fig = go.Figure(data=[go.Bar(
        x=words,
        y=counts,
        text=counts,
        textposition='auto',
        hovertemplate='Word: %{x}<br>Count: %{y}<extra></extra>',
        marker=dict(color='blue')
    )])

    fig.update_layout(
        title='Most Common Words',
        xaxis_title='Words',
        yaxis_title='Number of Times Used',
        xaxis_tickangle=-45
    )

    st.plotly_chart(fig)

def plot_repeated_words(text):
    tokens = preprocess_text(text)
    word_freq = nltk.FreqDist(tokens)
    repeated_words = [word for word, count in word_freq.items() if count > 1][:10]

    words, counts = zip(*[(word, word_freq[word]) for word in repeated_words])

    fig = go.Figure(data=[go.Bar(
        x=words,
        y=counts,
        text=counts,
        textposition='auto',
        hovertemplate='Word: %{x}<br>Count: %{y}<extra></extra>',
        marker=dict(color='blue')
    )])

    fig.update_layout(
        title='Repeated Words',
        xaxis_title='Words',
        yaxis_title='Number of Times Used',
        xaxis_tickangle=-45
    )

    st.plotly_chart(fig)

def calculate_perplexity(text, model):
    tokens = preprocess_text(text)
    padded_tokens = ['<s>'] + tokens + ['</s>']
    ngrams_sequence = list(ngrams(padded_tokens, model.order))
    perplexity = model.perplexity(ngrams_sequence)
    return perplexity

def calculate_burstiness(text):
    tokens = preprocess_text(text)
    word_freq = nltk.FreqDist(tokens)

    avg_freq = sum(word_freq.values()) / len(word_freq)
    variance = sum((freq - avg_freq) ** 2 for freq in word_freq.values()) / len(word_freq)

    burstiness_score = variance / (avg_freq ** 2)
    return burstiness_score

def is_generated_text(perplexity, burstiness_score, perplexity_threshold=100, burstiness_threshold=1):
    if perplexity < perplexity_threshold and burstiness_score < burstiness_threshold:
        return "Likely generated by a language model"
    else:
        return "Not likely generated by a language model"

# Function to detect plagiarism
def detect_plagiarism(input_text):
    vectorized_text = tfidf_vectorizer.transform([input_text])
    probabilities = plagiarism_model.predict_proba(vectorized_text)
    plagiarism_probability = probabilities[0][1]  # Probability of class 1 (Plagiarism)
    plagiarism_percentage = plagiarism_probability * 100
    
    return plagiarism_percentage

def plot_plagiarism_gauge_chart(plagiarism_percentage):
    fig = go.Figure(go.Indicator(
        mode="gauge+number",
        value=plagiarism_percentage,
        title={'text': "Plagiarism Percentage"},
        gauge={
            'axis': {'range': [0, 100]},
            'bar': {'color': "darkblue"},
            'steps': [
                {'range': [0, 50], 'color': "lightgreen"},
                {'range': [50, 100], 'color': "lightcoral"}],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 50}}))
    st.plotly_chart(fig)

def main():
    st.title("AI Text Analysis App & Plagiarism Checker")
    text = st.text_area("Enter the text you want to analyze", height=200)
    
    uploaded_file = st.file_uploader("Or upload a file", type=["txt", "pdf", "docx"])
    
    if uploaded_file is not None:
        with st.spinner('Uploading file...'):
            if uploaded_file.type == "application/pdf":
                reader = PdfReader(uploaded_file)
                text = ""
                for page in reader.pages:
                    text += page.extract_text()
            elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                doc = Document(uploaded_file)
                text = "\n".join([para.text for para in doc.paragraphs])
            else:
                text = uploaded_file.read().decode("utf-8")
    
    if text:
        if st.button("Analyze"):
            with st.spinner('Analyzing text...'):
                progress_bar = st.progress(0)
                
                # Load or train your language model
                progress_bar.progress(10)
                tokens = nltk.corpus.brown.words()  # You can use any corpus of your choice
                train_data, padded_vocab = padded_everygram_pipeline(1, tokens)
                model = MLE(1)
                model.fit(train_data, padded_vocab)

                # Calculate perplexity
                progress_bar.progress(30)
                perplexity = calculate_perplexity(text, model)
                

                # Calculate burstiness score
                progress_bar.progress(50)
                burstiness_score = calculate_burstiness(text)
               

                # Check if text is likely generated by a language model
                progress_bar.progress(70)
                generated_cue = is_generated_text(perplexity, burstiness_score)
               
                
                # Plot most common words
                progress_bar.progress(80)
                plot_most_common_words(text)

                # Plot repeated words
                progress_bar.progress(90)
                plot_repeated_words(text)
                
                # Plagiarism detection
                progress_bar.progress(95)
                plagiarism_percentage = detect_plagiarism(text)
                st.write(f"Plagiarism Percentage: {plagiarism_percentage:.2f}%")
                
                # Plot plagiarism gauge chart
                plot_plagiarism_gauge_chart(plagiarism_percentage)
                
                progress_bar.progress(100)
    else:
        st.warning("Please enter some text to analyze or upload a file.")

if __name__ == "__main__":
    main()
